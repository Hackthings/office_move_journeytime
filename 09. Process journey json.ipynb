{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mylibrary.connections import cursor, conn, engine, Automapped_Base, session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_duration(station):\n",
    "    tfl_response_json = json.loads(station.tfl_response)\n",
    "    return_object = {}\n",
    "    return_object[\"duration\"] = tfl_response_json[\"journeys\"][0][\"duration\"]\n",
    "    return return_object    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "Stations_orig = Automapped_Base.classes.stations_journeytime_stpauls\n",
    "Stations_dest = Automapped_Base.classes.stations_journeytime_camden\n",
    "\n",
    "for Stations in (Stations_orig, Stations_dest):\n",
    "    nlcs = session.query(Stations.nlc).filter(Stations.tfl_message == \"ok\").all()\n",
    "    for nlc in nlcs:\n",
    "        station = session.query(Stations).filter(Stations.nlc == nlc).one()\n",
    "        journey = get_duration(station)\n",
    "        station.journey_time = journey[\"duration\"]\n",
    "        session.add(station)\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we want to figure out which London mainline station this journey will go through\n",
    "\n",
    "# We first want to scan through these ones to see whether the journey goes through.  \n",
    "# Otherwise we want to return the last national rail station the journey went through\n",
    "\n",
    "mainline_stations = {\"Waterloo\" : \"WAT\",\n",
    "\"Paddington\" : \"PAD\",\n",
    "\"King's Cross\" : \"KGX\",\n",
    "\"St Pancras\" : \"STP\",\n",
    "\"Euston\" : \"EUS\",\n",
    "\"Charing Cross\" : \"CHX\",\n",
    "\"Victoria\" : \"VIC\",\n",
    "\"London Bridge\" : \"LBG\",\n",
    "\"Fenchurch Street\" : \"FST\",\n",
    "\"Liverpool Street\" : \"LST\"}\n",
    "\n",
    "import pandas as pd\n",
    "sql = \"\"\"\n",
    "select nlc as mainline_nlc, tlc as mainline_tlc, icscode as mainline_icscode from tt.all_stations\n",
    "\"\"\"\n",
    "all_stations = pd.read_sql(sql,conn)\n",
    "\n",
    "mainline_df = pd.DataFrame(pd.Series(mainline_stations)).reset_index()\n",
    "mainline_df.columns = [\"station\", \"stn_code\"]\n",
    "mainline_df = mainline_df.merge(all_stations, left_on=\"stn_code\", right_on=\"mainline_tlc\", how=\"left\")\n",
    "mainline_df.drop(\"stn_code\", axis=1)\n",
    "\n",
    "mainline_icscodes = list(mainline_df[\"mainline_icscode\"])\n",
    "mainline_ics_lookup = mainline_df[[\"station\", \"mainline_icscode\"]].to_dict(orient=\"records\")\n",
    "mainline_ics_lookup = {i['mainline_icscode'] : i[\"station\"] for i in mainline_ics_lookup}\n",
    "\n",
    "all_national_rail_ics = list(all_stations[\"mainline_icscode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinlinacre/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:34: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "# We will iterate through the legs of the journey finding the first match to a London mainline station\n",
    "\n",
    "def get_legs(legs):\n",
    "    all_legs = []\n",
    "    for leg in legs:\n",
    "        this_leg_data = {}\n",
    "        try:\n",
    "            this_leg_data[\"departed_from_name\"] = leg[\"departurePoint\"][\"commonName\"]\n",
    "            this_leg_data[\"departed_from_icscode\"] = leg[\"departurePoint\"][\"icsCode\"]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            this_leg_data[\"arrived_at_name\"] = leg[\"arrivalPoint\"][\"commonName\"]\n",
    "            this_leg_data[\"arrived_at_icscode\"] = leg[\"arrivalPoint\"][\"icsCode\"]\n",
    "        except:\n",
    "            pass\n",
    "        all_legs.append(this_leg_data.copy())\n",
    "    \n",
    "    all_legs = pd.DataFrame(all_legs).reset_index()\n",
    "    all_legs.rename(columns={\"index\":\"tfl_order\"}, inplace=True)\n",
    "    return all_legs\n",
    "    \n",
    "    \n",
    "def get_mainline_station(station):\n",
    "    tfl_response_json = json.loads(station.tfl_response)\n",
    "    first_journey = tfl_response_json[\"journeys\"][0]\n",
    "    legs = get_legs(first_journey[\"legs\"])\n",
    "    legs[\"mainline_station\"] = False\n",
    "    legs[\"national_rail_station\"] = False\n",
    "    legs[\"mainline_station\"] = legs[\"arrived_at_icscode\"].isin(mainline_icscodes)\n",
    "    legs[\"national_rail_station\"] = legs[\"arrived_at_icscode\"].isin(all_national_rail_ics)\n",
    "    \n",
    "    legs = legs.sort([\"mainline_station\", \"national_rail_station\", \"tfl_order\"], ascending=[False,False,True])\n",
    "    return legs.iloc[0][\"arrived_at_icscode\"]\n",
    "    \n",
    "#   order by whether mainline, and then original order.  Take first result\n",
    "for Stations in (Stations_orig, Stations_dest):\n",
    "    nlcs = session.query(Stations.nlc).filter(Stations.tfl_message == \"ok\").all() \n",
    "    for nlc in nlcs:\n",
    "        station = session.query(Stations).filter(Stations.nlc == nlc).one()\n",
    "        mainline_ics = get_mainline_station(station)\n",
    "        station.london_mainline_station_ics = mainline_ics\n",
    "\n",
    "        if mainline_ics in mainline_ics_lookup:\n",
    "            station.london_mainline_station_text = mainline_ics_lookup[mainline_ics]\n",
    "        else:\n",
    "            station.london_mainline_station_text = \"Other\"\n",
    "\n",
    "        session.add(station)\n",
    "        session.commit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"select a.nlc, v.geom, a.station_name, o.journey_time, o.london_mainline_station_text from tt.stations_voronoi_icscode_ok as v\\nleft join tt.all_stations as a \\non cast(a.nlc as text) = v.nlc\\nleft join tt.stations_journeytime_orig as o\\non cast(o.nlc as text) = v.nlc\\nwhere tfl_message is not null\\nand a.london_or_gb = 'gb'\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"select a.nlc, v.geom, a.station_name, o.journey_time, o.london_mainline_station_text from tt.stations_voronoi_icscode_ok as v\n",
    "left join tt.all_stations as a \n",
    "on cast(a.nlc as text) = v.nlc\n",
    "left join tt.stations_journeytime_orig as o\n",
    "on cast(o.nlc as text) = v.nlc\n",
    "where tfl_message is not null\n",
    "and a.london_or_gb = 'gb'\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
